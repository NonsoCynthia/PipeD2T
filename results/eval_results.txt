EVALUATION RESULTS FOR DATA-TO-TEXT WEBNLG 

Evaluation of Ordering and Structuring 

All domains:  

Task: ordering
Set: test
Model: t5
Accuracy: 0.46
--------------------

Task: ordering
Set: test
Model: bart
Accuracy: 0.0
--------------------

Task: ordering
Set: test
Model: gpt2
Accuracy: 0.24
--------------------

Task: ordering
Set: test
Model: chatgpt
Accuracy: 0.3
--------------------

Task: structuring
Set: test
Model: t5
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: bart
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: gpt2
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: chatgpt
Accuracy: 0.0
--------------------

Task: ordering
Set: dev
Model: t5
Accuracy: 0.59
--------------------

Task: ordering
Set: dev
Model: bart
Accuracy: 0.0
--------------------

Task: ordering
Set: dev
Model: gpt2
Accuracy: 0.34
--------------------

Task: ordering
Set: dev
Model: chatgpt
Accuracy: 0.26
--------------------

Task: structuring
Set: dev
Model: t5
Accuracy: 0.0
--------------------

Task: structuring
Set: dev
Model: bart
Accuracy: 0.0
--------------------

Task: structuring
Set: dev
Model: gpt2
Accuracy: 0.0
--------------------

Task: structuring
Set: dev
Model: chatgpt
Accuracy: 0.0
--------------------

############################################################

Seen domains:  

Task: ordering
Set: test
Model: t5
Accuracy: 0.59
--------------------

Task: ordering
Set: test
Model: bart
Accuracy: 0.0
--------------------

Task: ordering
Set: test
Model: gpt2
Accuracy: 0.34
--------------------

Task: ordering
Set: test
Model: chatgpt
Accuracy: 0.28
--------------------

Task: structuring
Set: test
Model: t5
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: bart
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: gpt2
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: chatgpt
Accuracy: 0.0
--------------------

Task: ordering
Set: dev
Model: t5
Accuracy: 0.59
--------------------

Task: ordering
Set: dev
Model: bart
Accuracy: 0.0
--------------------

Task: ordering
Set: dev
Model: gpt2
Accuracy: 0.34
--------------------

Task: ordering
Set: dev
Model: chatgpt
Accuracy: 0.26
--------------------

Task: structuring
Set: dev
Model: t5
Accuracy: 0.0
--------------------

Task: structuring
Set: dev
Model: bart
Accuracy: 0.0
--------------------

Task: structuring
Set: dev
Model: gpt2
Accuracy: 0.0
--------------------

Task: structuring
Set: dev
Model: chatgpt
Accuracy: 0.0
--------------------

############################################################

Unseen domains:  

Task: ordering
Set: test
Model: t5
Accuracy: 0.32
--------------------

Task: ordering
Set: test
Model: bart
Accuracy: 0.0
--------------------

Task: ordering
Set: test
Model: gpt2
Accuracy: 0.12
--------------------

Task: ordering
Set: test
Model: chatgpt
Accuracy: 0.33
--------------------

Task: structuring
Set: test
Model: t5
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: bart
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: gpt2
Accuracy: 0.0
--------------------

Task: structuring
Set: test
Model: chatgpt
Accuracy: 0.0
--------------------

Task: ordering
Set: dev
Model: t5
Accuracy: 0
--------------------

Task: ordering
Set: dev
Model: bart
Accuracy: 0
--------------------

Task: ordering
Set: dev
Model: gpt2
Accuracy: 0
--------------------

Task: ordering
Set: dev
Model: chatgpt
Accuracy: 0
--------------------

Task: structuring
Set: dev
Model: t5
Accuracy: 0
--------------------

Task: structuring
Set: dev
Model: bart
Accuracy: 0
--------------------

Task: structuring
Set: dev
Model: gpt2
Accuracy: 0
--------------------

Task: structuring
Set: dev
Model: chatgpt
Accuracy: 0
--------------------

############################################################


Evaluation of Referring Expressions 

All domains:  

Task: REG
Set: test
Model: t5
Baseline Accuracy: 0.51
Accuracy: 0.55
--------------------

Task: REG
Set: test
Model: bart
Baseline Accuracy: 0.51
Accuracy: 0.54
--------------------

Task: REG
Set: test
Model: gpt2
Baseline Accuracy: 0.51
Accuracy: 0.39
--------------------

Task: REG
Set: dev
Model: t5
Baseline Accuracy: 0.54
Accuracy: 0.63
--------------------

Task: REG
Set: dev
Model: bart
Baseline Accuracy: 0.54
Accuracy: 0.72
--------------------

Task: REG
Set: dev
Model: gpt2
Baseline Accuracy: 0.54
Accuracy: 0.63
--------------------

############################################################

Seen domains:  

Task: REG
Set: test
Model: t5
Baseline Accuracy: 0.53
Accuracy: 0.65
--------------------

Task: REG
Set: test
Model: bart
Baseline Accuracy: 0.53
Accuracy: 0.72
--------------------

Task: REG
Set: test
Model: gpt2
Baseline Accuracy: 0.53
Accuracy: 0.64
--------------------

Task: REG
Set: dev
Model: t5
Baseline Accuracy: 0.54
Accuracy: 0.63
--------------------

Task: REG
Set: dev
Model: bart
Baseline Accuracy: 0.54
Accuracy: 0.72
--------------------

Task: REG
Set: dev
Model: gpt2
Baseline Accuracy: 0.54
Accuracy: 0.63
--------------------

############################################################

Unseen domains:  

Task: REG
Set: test
Model: t5
Baseline Accuracy: 0.5
Accuracy: 0.46
--------------------

Task: REG
Set: test
Model: bart
Baseline Accuracy: 0.5
Accuracy: 0.35
--------------------

Task: REG
Set: test
Model: gpt2
Baseline Accuracy: 0.5
Accuracy: 0.13
--------------------

Task: REG
Set: dev
Model: t5
Baseline Accuracy: 0
Accuracy: 0
--------------------

Task: REG
Set: dev
Model: bart
Baseline Accuracy: 0
Accuracy: 0
--------------------

Task: REG
Set: dev
Model: gpt2
Baseline Accuracy: 0
Accuracy: 0
--------------------

############################################################


Evaluation of Lexicalization 

All domains:  

Task: Lexicalization
Set: test
Model: t5
Result: 0.2
--------------------

Task: Lexicalization
Set: test
Model: bart
Result: 0.0
--------------------

Task: Lexicalization
Set: test
Model: gpt2
Result: 0.42
--------------------

Task: Lexicalization
Set: dev
Model: t5
Result: 0.21
--------------------

Task: Lexicalization
Set: dev
Model: bart
Result: 0.0
--------------------

Task: Lexicalization
Set: dev
Model: gpt2
Result: 0.2
--------------------

############################################################

Seen domains:  

Task: Lexicalization
Set: test
Model: t5
Result: 0.21
--------------------

Task: Lexicalization
Set: test
Model: bart
Result: 0.0
--------------------

Task: Lexicalization
Set: test
Model: gpt2
Result: 0.45
--------------------

Task: Lexicalization
Set: dev
Model: t5
Result: 0.21
--------------------

Task: Lexicalization
Set: dev
Model: bart
Result: 0.0
--------------------

Task: Lexicalization
Set: dev
Model: gpt2
Result: 0.2
--------------------

############################################################

Unseen domains:  

Task: Lexicalization
Set: test
Model: t5
Result: 0.2
--------------------

Task: Lexicalization
Set: test
Model: bart
Result: 0.0
--------------------

Task: Lexicalization
Set: test
Model: gpt2
Result: 0.38
--------------------

Task: Lexicalization
Set: dev
Model: t5
Result: 0
--------------------

Task: Lexicalization
Set: dev
Model: bart
Result: 0
--------------------

Task: Lexicalization
Set: dev
Model: gpt2
Result: 0
--------------------

############################################################


Evaluation of Final Texts (BLEU)

All domains:

Task: end2end
Set: test
Model: t5
Result: 0.56
--------------------

Task: end2end
Set: test
Model: bart
Result: 0.45
--------------------

Task: end2end
Set: test
Model: gpt2
Result: 0.33
--------------------

Task: sr
Set: test
Model: t5
Result: 0.46
--------------------

Task: sr
Set: test
Model: bart
Result: 0.23
--------------------

Task: sr
Set: test
Model: gpt2
Result: 0.32
--------------------

Task: end2end
Set: dev
Model: t5
Result: 0.65
--------------------

Task: end2end
Set: dev
Model: bart
Result: 0.64
--------------------

Task: end2end
Set: dev
Model: gpt2
Result: 0.62
--------------------

Task: sr
Set: dev
Model: t5
Result: 0.55
--------------------

Task: sr
Set: dev
Model: bart
Result: 0.29
--------------------

Task: sr
Set: dev
Model: gpt2
Result: 0.49
--------------------

############################################################

Seen domains:

Task: end2end
Set: test
Model: t5
Result: 0.63
--------------------

Task: end2end
Set: test
Model: bart
Result: 0.62
--------------------

Task: end2end
Set: test
Model: gpt2
Result: 0.58
--------------------

Task: sr
Set: test
Model: t5
Result: 0.53
--------------------

Task: sr
Set: test
Model: bart
Result: 0.28
--------------------

Task: sr
Set: test
Model: gpt2
Result: 0.47
--------------------

Task: end2end
Set: dev
Model: t5
Result: 0.65
--------------------

Task: end2end
Set: dev
Model: bart
Result: 0.64
--------------------

Task: end2end
Set: dev
Model: gpt2
Result: 0.62
--------------------

Task: sr
Set: dev
Model: t5
Result: 0.55
--------------------

Task: sr
Set: dev
Model: bart
Result: 0.29
--------------------

Task: sr
Set: dev
Model: gpt2
Result: 0.49
--------------------

############################################################

Unseen domains:

Task: end2end
Set: test
Model: t5
Result: 0.46
--------------------

Task: end2end
Set: test
Model: bart
Result: 0.26
--------------------

Task: end2end
Set: test
Model: gpt2
Result: 0.13
--------------------

Task: sr
Set: test
Model: t5
Result: 0.37
--------------------

Task: sr
Set: test
Model: bart
Result: 0.17
--------------------

Task: sr
Set: test
Model: gpt2
Result: 0.13
--------------------

Task: end2end
Set: dev
Model: t5
Result: 0
--------------------

Task: end2end
Set: dev
Model: bart
Result: 0
--------------------

Task: end2end
Set: dev
Model: gpt2
Result: 0
--------------------

Task: sr
Set: dev
Model: t5
Result: 0
--------------------

Task: sr
Set: dev
Model: bart
Result: 0
--------------------

Task: sr
Set: dev
Model: gpt2
Result: 0
--------------------

############################################################


Evaluation of Final Texts (METEOR)

All domains:

Task: end2end
Set: test
Model: t5
Result: 0.0
--------------------

Task: end2end
Set: test
Model: bart
Result: 0.0
--------------------

Task: end2end
Set: test
Model: gpt2
Result: 0.0
--------------------

Task: sr
Set: test
Model: t5
Result: 0.0
--------------------

Task: sr
Set: test
Model: bart
Result: 0.0
--------------------

Task: sr
Set: test
Model: gpt2
Result: 0.0
--------------------

Task: end2end
Set: dev
Model: t5
Result: 0.0
--------------------

Task: end2end
Set: dev
Model: bart
Result: 0.0
--------------------

Task: end2end
Set: dev
Model: gpt2
Result: 0.0
--------------------

Task: sr
Set: dev
Model: t5
Result: 0.0
--------------------

Task: sr
Set: dev
Model: bart
Result: 0.0
--------------------

Task: sr
Set: dev
Model: gpt2
Result: 0.0
--------------------

############################################################

Seen domains:
